{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - NLP \n",
    "# Name: Muhammad Ahsan Farooqui\n",
    "# Roll Number: 20I-2207\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQ5uo_DmdtYf"
   },
   "source": [
    "# Importing Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PiaZDZdaAzSx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import spacy\n",
    "import random\n",
    "import math\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pAxekDQgeZ7M",
    "outputId": "92044268-e817-4b3b-bd7f-40fae433e00f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ojve1WJWD5n2"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('./Data/iqbal.txt', 'rt', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    passage = list(reader)\n",
    "f.close()\n",
    "\n",
    "with open('./Data/ghalib.txt', 'rt', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    passage.append(list(reader))\n",
    "f.close()\n",
    "\n",
    "with open('./Data/faiz.txt', 'rt', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    passage.append(list(reader))\n",
    "f.close()\n",
    "\n",
    "\n",
    "passage = [item for sublist in passage for item in sublist]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnAwY9ujd8_Y"
   },
   "source": [
    "## Removing English, punctuation marks and other special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ibl5fkSnT51g",
    "outputId": "1f0084fa-8112-4171-e950-6ef89245df9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Musafir K Rastay Badaltay Rahay']\n",
      "['Muqaddar Main Chalna Tha Chaltay Rahay']\n",
      "['Muhabbat Adawat Wafa Berukhi']\n",
      "['Kiray K Ghar Thay Badalty Rahay']\n"
     ]
    }
   ],
   "source": [
    "for i in passage:\n",
    "  b = re.findall(\"[a-zA-Z]\",str(i))\n",
    "  if(len(b)>2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3fYIthiSMfSd"
   },
   "outputs": [],
   "source": [
    "english_verses = []\n",
    "for i in passage:\n",
    "  b = re.findall(\"[a-zA-Z]\",str(i))\n",
    "  if(len(b)>2):\n",
    "    english_verses.append(i)\n",
    "\n",
    "passage = [x for x in passage if x not in english_verses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SZ--9meFV922"
   },
   "outputs": [],
   "source": [
    "replace_items = [\"['\",\"']\",\"[\",\"]\",\"'\",\"“\",\"‘\",'\"',\"’\",\"'\",'؛','،','٫','؟','۔','٪','!',\"%\",\" ِ\",\".\",\":\",\"(\",\")\",\"*\"]\n",
    "for i in range(len(passage)):\n",
    "  if(len(passage[i])>0):\n",
    "    a = passage[i]\n",
    "    for j in replace_items:\n",
    "      a = str(a).replace(j,\"\")\n",
    "      a = \" \".join(a.split())\n",
    "    passage[i]= a\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRrOSE7lBaIc"
   },
   "source": [
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loZ2DTryeBfo"
   },
   "source": [
    "## Creating Model for Spacy tokenization for Urdu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VP9k5OONd6RJ"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.blank('ur')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fm4VlGamBFJ8"
   },
   "source": [
    "# Defining Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uucPxY8qbAck"
   },
   "source": [
    "## Defining Unigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "COK9EXSAo5PD"
   },
   "outputs": [],
   "source": [
    "def create_unigrams(passage):\n",
    "  unigrams = [nlp(\"شششش \"+(str(p).replace(\"[\",\"\").replace(\"]\",\"\").strip())+\" خخخخ\") for p in passage if(len(p)>0)]\n",
    "  unigrams = [item for sublist in unigrams for item in sublist]\n",
    "  unigrams = np.array(unigrams)\n",
    "  unigrams = [str(x).strip() for x in unigrams]\n",
    "  unique_elements, counts_elements = np.unique(unigrams, return_counts=True)\n",
    "  unigram_dict_probability = {}\n",
    "  unigram_dict_counts = {}\n",
    "\n",
    "  for i,j in zip(unique_elements,counts_elements):\n",
    "    unigram_dict_probability[i] = j/sum(counts_elements)\n",
    "  unigram_dict_probability = dict(sorted(unigram_dict_probability.items(), key=lambda item: item[1],reverse=True))\n",
    "\n",
    "  for i,j in zip(unique_elements,counts_elements):\n",
    "    unigram_dict_counts[i] = j\n",
    "  unigram_dict_counts = dict(sorted(unigram_dict_counts.items(), key=lambda item: item[1],reverse=True))\n",
    "\n",
    "  #Resetting the tokens\n",
    "  unigram_dict_probability[\"<s>\"] = unigram_dict_probability[\"شششش\"]\n",
    "  del unigram_dict_probability[\"شششش\"]\n",
    "\n",
    "  unigram_dict_probability[\"</s>\"] = unigram_dict_probability[\"خخخخ\"]\n",
    "  del unigram_dict_probability[\"خخخخ\"]\n",
    "\n",
    "\n",
    "  #Resetting the tokens\n",
    "  unigram_dict_counts[\"<s>\"] = unigram_dict_counts[\"شششش\"]\n",
    "  del unigram_dict_counts[\"شششش\"]\n",
    "\n",
    "  unigram_dict_counts[\"</s>\"] = unigram_dict_counts[\"خخخخ\"]\n",
    "  del unigram_dict_counts[\"خخخخ\"]\n",
    "  return unigram_dict_counts,unigram_dict_probability,unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qkmk1NN7xsAG"
   },
   "outputs": [],
   "source": [
    "def get_unigram_count(word,unigram_dict_counts):\n",
    "  try:\n",
    "    return unigram_dict_counts[word]\n",
    "  except:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PazFTFMj2jfq"
   },
   "outputs": [],
   "source": [
    "def get_unigram_word(prev_word=0,sentence_length=5,unigram_dict_probability=0,unigram_sentence = []):\n",
    "  length = len(unigram_dict_probability.keys())\n",
    "  if sentence_length==0:\n",
    "    print(\"\")\n",
    "    pass\n",
    "  else:\n",
    "    if(prev_word==0):\n",
    "      word = length*random.random()\n",
    "      selectedword = list(unigram_dict_probability.keys())[int(word)]\n",
    "      unigram_sentence.append(selectedword)\n",
    "      print(selectedword,end=\" \")\n",
    "    else:\n",
    "      prev_word_position = list(unigram_dict_probability.keys()).index(prev_word)\n",
    "      selectedword = list(unigram_dict_probability.keys())[int(prev_word_position-1)]\n",
    "      unigram_sentence.append(selectedword)\n",
    "      print(selectedword,end=\" \")\n",
    "    get_unigram_word(sentence_length = sentence_length-1,unigram_dict_probability=unigram_dict_probability,unigram_sentence=unigram_sentence)\n",
    "  return unigram_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1sEsw1al3dn6"
   },
   "outputs": [],
   "source": [
    "def generate_unigram_sentence(sentence_length,unigram_dict_probability,unigram_sentence):\n",
    "  sentence = get_unigram_word(prev_word=0,sentence_length=sentence_length,unigram_dict_probability=unigram_dict_probability,unigram_sentence=unigram_sentence)\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvfQ1Djn1S42"
   },
   "source": [
    "### Evaluation of Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YNHaajGO1dpD"
   },
   "outputs": [],
   "source": [
    "def calculate_perplexity_unigram(sentence,unigram_probability):\n",
    "  probability = 1\n",
    "  probability_log = 0\n",
    "  for i in sentence:\n",
    "    probability = probability*unigram_dict_probability[i]\n",
    "    probability_log = probability_log + math.log(unigram_dict_probability[i])\n",
    "  return probability,-1*probability_log,(1/(-1*probability_log))**len(sentence)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USLvk7zJa9P8"
   },
   "source": [
    "## Defining Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DJbNQ6f5E0ss"
   },
   "outputs": [],
   "source": [
    "def create_bigrams(passage, unigram_dict_counts,backward=False):\n",
    "  bigrams = []\n",
    "  dictionary = []\n",
    "  urdu_characters = ['آ','أ','ا','ب','پ','ت','ٹ','ث','ج','چ','ح','خ','د','ڈ','ذ','ر','ڑ','ز','ژ','س','ش','ص','ض','ط','ظ','ع','غ','ف','ق','ک','گ','ل','م','ن','ں','و','ؤ','ہ','ۂ','ۃ','ھ','ء','ی','ئ','ے','ۓ']\n",
    "  urdu_punctuations = ['؛','،','٫','؟','۔','٪','!']\n",
    "  for i in passage:\n",
    "    data = nlp(str(i).replace(\"[\",\"\").replace(\"]\",\"\").strip())\n",
    "    if(backward):\n",
    "      data = list(data)[::-1]\n",
    "    #print(data)\n",
    "    for word in range(len(data)):\n",
    "      if(word==0):\n",
    "        a = \"<s>\"\n",
    "        #print(\"len of a is \",len(a))\n",
    "        b = str(data[word]).strip()\n",
    "      elif(word==len(data)-1):\n",
    "        b = \"</s>\"  \n",
    "        a = str(data[word]).strip()\n",
    "      else:\n",
    "        a = str(data[word]).strip()\n",
    "        b = str(data[word+1]).strip()\n",
    "      if(((str(a)==\"<s>\") and (str(b)==\"</s>\"))| (len(a)==0) | (len(b)==0)|\n",
    "        (((len(a)==1) and (str(a) not in urdu_characters)))|# and (str(a) not in urdu_punctuations))|\n",
    "        (((len(b)==1) and (str(b) not in urdu_characters)))):# and (str(b) not in urdu_punctuations))):\n",
    "        print(i)\n",
    "        print(a)\n",
    "        print(b)\n",
    "        print(\"==\")\n",
    "        continue\n",
    "      else:\n",
    "        bigrams.append((a,b))\n",
    "  bigrams_dict = {}\n",
    "  bigrams_dict_probab = {}\n",
    "  for i in bigrams:\n",
    "    if(i in bigrams_dict.keys()):\n",
    "      bigrams_dict[i] = bigrams_dict[i]+1\n",
    "    else:\n",
    "      bigrams_dict[i] = 1\n",
    "\n",
    "  for i in bigrams_dict.keys():\n",
    "    try:\n",
    "      bigrams_dict_probab[i] = bigrams_dict[i]/get_unigram_count(i[0],unigram_dict_counts)\n",
    "    except:\n",
    "      print(\"Following word has 0 probability in unigrams\", i[0])\n",
    "\n",
    "  bigrams_dict = dict(sorted(bigrams_dict.items(), key=lambda item: item[1],reverse=True))\n",
    "  bigrams_dict_probab = dict(sorted(bigrams_dict_probab.items(), key=lambda item: item[1],reverse=True))\n",
    "  return bigrams,bigrams_dict,bigrams_dict_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "b_SPTfNWTBVl"
   },
   "outputs": [],
   "source": [
    "def get_bigram_word(prev_word=\"123\",sentence_length=0,total_length=10,bigrams_dict_probab=[],bigram_word=[]):\n",
    "  \n",
    "  if ((sentence_length==total_length) | (prev_word==\"</s>\")):\n",
    "    print(\"\")\n",
    "  else:\n",
    "    start_words_keys = [x for x in bigrams_dict_probab.keys() if x[0]==\"<s>\"]\n",
    "    if(prev_word==\"123\"):\n",
    "      length = len(start_words_keys)\n",
    "      keys = length*random.random()\n",
    "      selectedword = start_words_keys[int(keys)]\n",
    "\n",
    "      print(selectedword[1],end=\" \")\n",
    "      bigram_word.append(selectedword[1])\n",
    "      get_bigram_word(str(selectedword[1]),sentence_length = sentence_length+1,total_length=total_length,bigrams_dict_probab=bigrams_dict_probab,bigram_word=bigram_word)\n",
    "    else:\n",
    "      if(sentence_length > (total_length-3)):\n",
    "        #keys = list(bigrams_dict_probab.keys())\n",
    "        end_words_keys = [x for x in bigrams_dict_probab.keys() if x[1]==\"</s>\"]\n",
    "        keys = end_words_keys\n",
    "      else:\n",
    "        end_words_keys = [x for x in bigrams_dict_probab.keys() if x[1]==\"</s>\"]\n",
    "        keys = list(bigrams_dict_probab.keys())\n",
    "        keys = list(set(keys)-set(end_words_keys)-set(start_words_keys))\n",
    "      sets = [y for y in keys if y[0]==prev_word]\n",
    "      nextword = [x for x in bigrams_dict_probab.keys() if x in sets]\n",
    "      nextword = np.array(nextword)\n",
    "      #print(nextword)\n",
    "      nextword = nextword[:5]\n",
    "      if(len(nextword)>0):\n",
    "        vaal = len(nextword)*random.random()\n",
    "        if(str(nextword[int(vaal)][1])!=\"</s>\"):\n",
    "          print(str(nextword[int(vaal)][1]),end=\" \")\n",
    "          bigram_word.append(str(nextword[int(vaal)][1]))\n",
    "        get_bigram_word(str(nextword[int(vaal)][1]),sentence_length = sentence_length+1,total_length=total_length,bigrams_dict_probab=bigrams_dict_probab,bigram_word=bigram_word)\n",
    "      else:\n",
    "        get_bigram_word(\"123\",sentence_length = sentence_length,total_length=total_length,bigrams_dict_probab=bigrams_dict_probab,bigram_word=bigram_word)    \n",
    "  return bigram_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-UuCNV7Pe1am"
   },
   "outputs": [],
   "source": [
    "def get_bigram_count(a,b,bigrams_dict):\n",
    "  key = (a,b)\n",
    "  return bigrams_dict[key]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-N5LXwpdbbEj"
   },
   "source": [
    "## Defining Trigrams Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jw2BR1PLbcTu"
   },
   "outputs": [],
   "source": [
    "def create_trigrams(passage,bigram_count):\n",
    "  trigrams = []\n",
    "  dictionary = []\n",
    "  trigrams_dict = {}\n",
    "  trigrams_dict_probab = {}\n",
    "  urdu_characters = ['آ','أ','ا','ب','پ','ت','ٹ','ث','ج','چ','ح','خ','د','ڈ','ذ','ر','ڑ','ز','ژ','س','ش','ص','ض','ط','ظ','ع','غ','ف','ق','ک','گ','ل','م','ن','ں','و','ؤ','ہ','ۂ','ۃ','ھ','ء','ی','ئ','ے','ۓ']\n",
    "  for i in passage:\n",
    "    data = nlp(str(i).replace(\"[\",\"\").replace(\"]\",\"\").strip())\n",
    "    for word in range(len(data)-1):\n",
    "      if(word==0):\n",
    "        a = \"<s>\"\n",
    "        b = str(data[word]).strip()\n",
    "        c = str(data[word+1]).strip()\n",
    "      elif(word==len(data)-2):\n",
    "        c = \"</s>\"  \n",
    "        a = str(data[word]).strip()\n",
    "        b = str(data[word+1]).strip()\n",
    "      else:\n",
    "        a = str(data[word]).strip()\n",
    "        b = str(data[word+1]).strip()\n",
    "        c = str(data[word+2]).strip()\n",
    "      if(((str(a)==\"<s>\") and (str(c)==\"</s>\"))| (len(a)==0) | (len(b)==0)| (len(c)==0) |\n",
    "        (((len(a)==1) and (str(a) not in urdu_characters)))|# and (str(a) not in urdu_punctuations))|\n",
    "        (((len(b)==1) and (str(b) not in urdu_characters)))|# and (str(b) not in urdu_punctuations))|\n",
    "        (((len(c)==1) and (str(c) not in urdu_characters)))):# and (str(c) not in urdu_punctuations))):\n",
    "        print(i)\n",
    "        print(\"a=\",a)\n",
    "        print(\"b=\",b)\n",
    "        print(\"c=\",c)\n",
    "        print(\"==\")\n",
    "        continue\n",
    "      else:\n",
    "        trigrams.append((a,b,c))\n",
    "\n",
    "  for i in trigrams:\n",
    "    if(i in trigrams_dict.keys()):\n",
    "      trigrams_dict[i] = trigrams_dict[i]+1\n",
    "    else:\n",
    "      trigrams_dict[i] = 1\n",
    "\n",
    "  for i in trigrams_dict.keys():\n",
    "    try:\n",
    "      trigrams_dict_probab[i] = trigrams_dict[i]/get_bigram_count(i[0],i[1],bigram_count)\n",
    "    except:\n",
    "      print(i[0])\n",
    "\n",
    "  trigrams_dict = dict(sorted(trigrams_dict.items(), key=lambda item: item[1],reverse=True))\n",
    "  trigrams_dict_probab = dict(sorted(trigrams_dict_probab.items(), key=lambda item: item[1],reverse=True))\n",
    "  return trigrams, trigrams_dict, trigrams_dict_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FdjuzmIYhC7z"
   },
   "outputs": [],
   "source": [
    "def get_trigram_word(first_word=\"123\",second_word=\"123\",sentence_length=0,total_length=6,trigrams_dict_probab=\"\"):\n",
    "  trigram_sentence = []\n",
    "  global a\n",
    "  if ((sentence_length==total_length) | (second_word==\"</s>\")):\n",
    "    print(\"\")\n",
    "  else:\n",
    "    start_words_keys = [x for x in trigrams_dict_probab.keys() if x[0]==\"<s>\"]\n",
    "    if((first_word==\"123\") and (second_word==\"123\") ):\n",
    "      length = len(start_words_keys)\n",
    "      keys = length*random.random()\n",
    "      selectedword = start_words_keys[int(keys)]\n",
    "\n",
    "      print(selectedword[1],selectedword[2],end=\" \")\n",
    "      trigram_sentence.append(selectedword[1])\n",
    "      trigram_sentence.append(selectedword[2])\n",
    "      get_trigram_word(str(selectedword[1]),str(selectedword[2]),sentence_length = sentence_length+1,total_length=total_length,trigrams_dict_probab=trigrams_dict_probab)\n",
    "    else:\n",
    "      if(sentence_length > (total_length-3)):\n",
    "        keys = list(trigrams_dict_probab.keys())\n",
    "      else:\n",
    "        end_words_keys = [x for x in trigrams_dict_probab.keys() if x[2]==\"</s>\"]\n",
    "        keys = list(trigrams_dict_probab.keys())\n",
    "        keys = list(set(keys)-set(end_words_keys)-set(start_words_keys))\n",
    "      sets = [y for y in keys if (y[0]==first_word) and (y[1]==second_word)]\n",
    "      nextword = [x for x in trigrams_dict_probab.keys() if x in sets]\n",
    "      nextword = np.array(nextword)\n",
    "      if(len(nextword)>0):\n",
    "        vaal = len(nextword)*random.random()\n",
    "        if(str(nextword[int(vaal)][2])!=\"</s>\"):\n",
    "          print(str(nextword[int(vaal)][2]),end=\" \")\n",
    "          trigram_sentence.append(str(nextword[int(vaal)][2]))\n",
    "        get_trigram_word(str(nextword[int(vaal)][1]),str(nextword[int(vaal)][2]),sentence_length = sentence_length+1,total_length=total_length,trigrams_dict_probab=trigrams_dict_probab)\n",
    "      else:\n",
    "        get_trigram_word(\"123\",\"123\",sentence_length = sentence_length,total_length=total_length,trigrams_dict_probab=trigrams_dict_probab)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RV6sU3L5fJ0A"
   },
   "source": [
    "# Running everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCOVcM0loy3J"
   },
   "source": [
    "## Creating Unigrams, Bigrams, Backward Bigrams and Trigrams\n",
    "\n",
    "*Important: It may take some time to generate all models.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "A0iUAWdmo259"
   },
   "outputs": [],
   "source": [
    "unigram_dict_counts,unigram_dict_probability,unigrams = create_unigrams(passage)\n",
    "bigrams,bigrams_dict,bigrams_dict_probab = create_bigrams(passage,unigram_dict_counts)\n",
    "bigrams_bkwd,bigrams_dict_bkwd,bigrams_dict_probab_bkwd = create_bigrams(passage,unigram_dict_counts,backward=True)\n",
    "trigrams, trigrams_dict, trigrams_dict_probab = create_trigrams(passage,bigrams_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKa7SUP5txpj"
   },
   "source": [
    "## Calculation for Bidirectional Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "JMvH-Tx6t00f"
   },
   "outputs": [],
   "source": [
    "def get_bidirectional_probability(bidirectional_bigrams,unigram_dict_counts):\n",
    "  bidirectional_dict_count = {}\n",
    "  bidirectional_dict_probab = {}\n",
    "  for i in bidirectional_bigrams:\n",
    "    if(i in bidirectional_dict_count.keys()):\n",
    "      bidirectional_dict_count[i] = bidirectional_dict_count[i]+1\n",
    "    else:\n",
    "      bidirectional_dict_count[i] = 1\n",
    "\n",
    "  for i in bidirectional_dict_count.keys():\n",
    "    try:\n",
    "      bidirectional_dict_probab[i] = bidirectional_dict_count[i]/get_unigram_count(i[0],unigram_dict_counts)\n",
    "    except:\n",
    "      print(\"Following word has 0 probability in unigrams\", i[0])\n",
    "  return bidirectional_dict_count, bidirectional_dict_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "B7Z2E3F2tHBP"
   },
   "outputs": [],
   "source": [
    "bidirectional_bigrams = bigrams+bigrams_bkwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vC9WohnFz8Sl"
   },
   "source": [
    "## Creating Bidirectional Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "hwUPcKzEtSw-"
   },
   "outputs": [],
   "source": [
    "bidirectional_dict, bidirectional_dict_probab = get_bidirectional_probability(bidirectional_bigrams,unigram_dict_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DeqbvlNIfRKN"
   },
   "source": [
    "## Unigrams Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "qL5yLJiTqJOq"
   },
   "outputs": [],
   "source": [
    "number_of_stanzas = random.randrange(7,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6Te-Q8GgRN5",
    "outputId": "cf958dc9-09e3-4e4f-ba78-9b14c4e1ae0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "آینہ صدائے زخمہ کي بیکراں گھائل رکھتا \n",
      "دہناں کنار چاہیئے بھید خرشید لعنت ستم \n",
      "مل رُک اگا روئے پہلو آتی محمد \n",
      "شادی بزمخیال سخت ترسنے بیانِ گفتگو پسر \n",
      "\n",
      "\n",
      "کے اربابِ ظالم چوکھٹ سبو رکھ کبريا \n",
      "اسرار تڑپ برسات فرزانہ مرید بازارِ جلوہٴ \n",
      "اک عطا ميں دہقاں بتخانہ کامی نرالے \n",
      "نکلوں کوچہ یہاں گزند مشکیں بچا گریے \n",
      "\n",
      "\n",
      "ہمتِِ ہوے نرالے بد دوا آنکھوں بیٹھنا \n",
      "یورپ تنِ سفلہ لیتا منصور عام بساطِ \n",
      "ماہِ آبیارِ کہہ جتنے شاہوں راج شمشیرِ \n",
      "گل خودی رقیب کرتے لینا خط مقدور \n",
      "\n",
      "\n",
      "پسر کبریا شاعر ربطیٴ فروغ فطرتیِ ختم \n",
      "نھیں بتاتا عبرت صحرائیوں دور واقف ساتھی \n",
      "لعنت جادو فطرتیِ یہود نطق عزم قط \n",
      "پروانہ خوف چڑھتے بدگمانیِ دیوارِ گُل لسان \n",
      "\n",
      "\n",
      "امام باتیں جفاخو عنواں روانی دانتوں رو \n",
      "مردوکوزندہ وَ مُژدہ ہجوم اسکی کروں تکلف \n",
      "راہ معمورے رازِ آتے وجودِ شب مانی \n",
      "جادہ ماتمیوں وَ دیکھو آزار لعل اِک \n",
      "\n",
      "\n",
      "آسمان کرتا باغ صاحب سویداۓ زلفِ آسکھوں \n",
      "اطفال نالٴہ پیوند شعلہٴ گھبرائیں پیٹوں قلمِ \n",
      "آہو قریہ نےاردو متاع کباب تاختن قطرہ \n",
      "سلیقہ آستیں سچ خداوندگار سہی قرآن چنتی \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for i in range(1,number_of_stanzas):\n",
    "    for j in range(1,5):\n",
    "      sentences.append(generate_unigram_sentence(7,unigram_dict_probability,unigram_sentence=[]))\n",
    "      if(j%4==0):\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXNCfQ-nAguB"
   },
   "source": [
    "### Running evaluation on Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HwSUY2Fr2c2l",
    "outputId": "826c3864-638d-48af-b434-ce3600a69ed1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['لیلیِ', 'سببِ', 'فروزاں', 'بوسے', 'روشناس', 'برسرِ', 'خاص'] (5.019378243291581e-32, 72.06941690569462, 9.90245646613125e-14)\n",
      "['نِگاه', 'راہبر', 'بھیس', 'آسا', 'خاکی', 'ملوکانہ', 'اَبرِ'] (1.5058134729874743e-31, 70.9708046170265, 1.1026607025224699e-13)\n",
      "['زمامِ', 'قریہ', 'گوارا', 'گرمی', 'زار', 'اسے', 'صاف'] (7.227904670339875e-29, 64.79701851312457, 2.0850421419733638e-13)\n",
      "['نجف', 'سکتی', 'رائیگاں', 'قبول', 'آیا', 'سرگشہٴ', 'وقف'] (9.637206227119836e-30, 66.81192153366683, 1.6827603223027541e-13)\n",
      "['چہ', 'مزا', 'رند', 'جُھوٹ', 'تنِ', 'مجبور', 'آشیاں'] (1.3552321256887266e-29, 66.47099494669624, 1.7441135020724725e-13)\n",
      "['ہاتھوں', 'پھر', 'فتنے', 'کبريا', 'پیٹھ', 'طاؤس', 'حوصلہ'] (9.33604353252234e-29, 64.54108513898737, 2.1436118988852386e-13)\n",
      "['خالی', 'کاوش', 'گنجینۂ', 'کاشانۂ', 'اہل', 'تسکینِ', 'شرم'] (1.3281274831749521e-28, 64.18861256101972, 2.2273787936400504e-13)\n",
      "['التفات', 'بجھتی', 'مسرت', 'خمارِ', 'منزلوں', 'سی', 'تاراجِ'] (6.023253891949897e-31, 69.58451025590662, 1.2659366557055644e-13)\n",
      "['جاؤ', 'ستوں', 'وسوسے', 'شکستہ', 'لفظ', 'اتارے', 'خودی'] (3.513564770304106e-29, 65.51833657065121, 1.9295674356214314e-13)\n",
      "['سہل', 'خواں', 'پنپ', 'خواری', 'مسکیں', 'کباب', 'ہوسِ'] (4.015502594633265e-31, 69.98997536401478, 1.2154836336328566e-13)\n",
      "['سمجھے', 'مزدوریِ', 'راز', 'سزا', 'ہنگامہ', 'فرقت', 'میان'] (4.577672957881922e-29, 65.25377691562028, 1.9849995965292498e-13)\n",
      "['دلاں', 'طلسم', 'آرائے', 'جان', 'زارِ', 'کمتر', 'پیشِ'] (4.0155025946332644e-30, 67.68739027102075, 1.5361923939866538e-13)\n",
      "['عہد', 'زانو', 'حقِ', 'پسر', 'دلستانی', 'پہنچے', 'خبراں'] (1.0038756486583162e-29, 66.77109953914658, 1.68997509450303e-13)\n",
      "['چلتا', 'عذاب', 'غرض', 'بیباک', 'طُرفِ', 'لائے', 'رستاخیز'] (1.606201037853306e-30, 68.60368100289489, 1.39819604063989e-13)\n",
      "['اپنے', 'خم', 'عبرت', 'زدگاں', 'ڈوبتی', 'سکتا', 'میان'] (2.1834295358318376e-28, 63.691485781611895, 2.3519622078216485e-13)\n",
      "['بدا', 'محمل', 'کہن', 'گِرفتار', 'دلفروز', 'بوتراب', 'باقی'] (5.722091197352403e-30, 67.33321845730012, 1.5936552710077178e-13)\n",
      "['بوئے', 'بافِ', 'مشاطگی', 'پندِ', 'تُو', 'پڑھیئے', 'کھول'] (6.023253891949898e-31, 69.58451025590662, 1.2659366557055644e-13)\n",
      "['مدّعا', 'رکھے', 'چراغاں', 'بھرنے', 'کاوشِ', 'گنوا', 'جامِ'] (3.9753475686869327e-29, 65.39485551388019, 1.9552167452146634e-13)\n",
      "['ناخوش', 'سرور', 'خر', 'ہنس', 'یاسِ', 'محورے', 'ستمہائے'] (4.517440418962423e-31, 69.87219232835841, 1.2298988911368867e-13)\n",
      "['نمودِ', 'رہنما', 'ہاۓ', 'کہوے', 'نقشہ', 'مختصر', 'افروزیِ'] (6.023253891949898e-31, 69.58451025590662, 1.2659366557055644e-13)\n",
      "['سائے', 'شوریدگی', 'ایاز', 'دم', 'بچھائی', 'تماشا', 'گریے'] (6.485036690332723e-29, 64.90547022135208, 2.060776512004417e-13)\n",
      "['بھید', 'بھلا', 'نگاھیں', 'روز', 'جاگے', 'ملکر', 'بیمارِ'] (4.065696377066181e-30, 67.67496775102218, 1.5381673820001687e-13)\n",
      "['ھم', 'ملامت', 'بھیس', 'موئے', 'تمثالِ', 'اُڑتے', 'مزا'] (1.0841857005509816e-29, 66.69413849801046, 1.703673352750621e-13)\n",
      "['سےکچھ', 'افسانے', 'سرمہ', 'خوف', 'کھرا', 'ہزاروں', 'ماہِ'] (1.0841857005509817e-29, 66.69413849801045, 1.7036733527506238e-13)\n"
     ]
    }
   ],
   "source": [
    "for i in sentences:\n",
    "  print(i,calculate_perplexity_unigram(i,unigram_dict_probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbG4OqSKubIW"
   },
   "source": [
    "## Bigrams Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ot2eQxkXx8Ow",
    "outputId": "30aedcf5-6bda-4165-ceb6-2e6390ab88ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بجا نہ بنے بات کہ یہ قدسیوں سے \n",
      "راہ پر ہے نہ ہوتا تو دے رہے \n",
      "لرزیدہ عزلت شہہ کے ساتھ عداوت ہی کیوں \n",
      "گئے وہ اب وہ بھی نہیں رہا ہے \n",
      "\n",
      "\n",
      "پہچانتا پھونکا نہیں رہا حرم ہے نہ ہو \n",
      "دی ہے یہ کام بند آیا عجب آزاد \n",
      "سنکر ایسی پرواز جہاں میں بھی نہیں رہا \n",
      "اپنے خنجر سے گزر بادہ و دل کا \n",
      "\n",
      "\n",
      "شہیدِ وفا کر نہیں آتی رہی پیرہن آرائی ضبط اعلان \n",
      "سیہ گری میں نے نہ بنے عمر بھر \n",
      "پھردھڑکنےکاحوصلہ گاہ خیال بیاباں ماندگی سے ہے نہ نموئے نفس \n",
      "محمد وصالِ یار ہوتا گر نظر کا دل \n",
      "\n",
      "\n",
      "مژدۂ رگِ جاں ستاں ناوک خیز ہے نہ حاصل سوز \n",
      "طَعمہ جذبۂ سمجھ سکتا نہیں ہے کہ یوں \n",
      "شرح کہتے ھو تشنگی لبریز نور تھا میں \n",
      "ڈال دو عالم گیر ہے یا کہ یوں \n",
      "\n",
      "\n",
      "درپردہ میری نفس جادہٴ سر راہ عمل کا \n",
      "فضائے زمانہ تنگ شاید کثرتِ نظاّرہ سے دل \n",
      "درویش ہوں اور ہے کہ یہ قدسیوں کے \n",
      "ہنس لوگ وہی دل کو بھی ہیں ہم \n",
      "\n",
      "\n",
      "سامنا چاہتا ہے نہ پوچھ اقبال میں نے \n",
      "دولت و نظر ہائے تیز دستی قاتل کیا \n",
      "جگنو ملت میں تو نہ ہوتا تو کیا \n",
      "اور شے ہےعلم ہے یا کوئی پوچھے ہے \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for i in range(1,number_of_stanzas):\n",
    "    for j in range(1,5):\n",
    "      sentence = get_bigram_word(\"123\",0,10,bigrams_dict_probab,bigram_word=[])\n",
    "      sentences.append(sentence)\n",
    "      if(j%4==0):\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-t50xRlls8mx"
   },
   "source": [
    "### Backward Bigrams Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k7Rll0XqacDp",
    "outputId": "4f7c4bc0-2569-4ecd-e0b3-020e9bd4de60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ایسے کب ملاقات بہرِ جز قلندر ڈالے کہہ \n",
      "ہائے نوا خونیں دیدۂ میں پردے سوز نیم بالا لانا \n",
      "ہائے نوا خونیں دیدۂ میں گھر کے عشق \n",
      "معلوم نہیں ایسے کب ملاقات ہے نہیں دل \n",
      "\n",
      "\n",
      "گزری سو تھا خدا والو رہنے کے جس \n",
      "آسکا دی نے تو ہو کہتے دل سے بھید خاشاک \n",
      "ساتھ خاک کا کس تو ہے میں بزم \n",
      "پیوند دستاویز کهولنا بیتابی نالہ دیکھی اثر ہے \n",
      "\n",
      "\n",
      "ایسی فائدہ سے مجھ نہیں ایسے کب حسن \n",
      "نزول ہو بھی کو اس کہ ہے کیا \n",
      "قریب بام نظارۂ لطفِ اگر دل وہ کہ \n",
      "یار تیغ واں گل برگ تو ہو کہتے \n",
      "\n",
      "\n",
      "دریغ لطفِ اگر بھی اور ہوں کرتا کی \n",
      "آخر بعد عرصے جتنے جان خوار غم آدمی گلا نمایاں \n",
      "عشق غمِ کاوشِ تاراجِ ڈھونڈھنا پار کے خدا \n",
      "اچھے کتنے تھے نہ ہے کیا میں دل \n",
      "\n",
      "\n",
      "آئنہ ترا یہ کا اس کہ تھا نہ \n",
      "شرمندہ میں دل کہ ہیں میں بزم تو \n",
      "ميں فکر کہ ہے کیا نے ہم گے شباب آشیانہ \n",
      "نفس یاں سے غم کوئی ہر کا اس \n",
      "\n",
      "\n",
      "خاموش آتشِ ہے میں گھر اپنے ہے میں \n",
      "گوہر قیمتِ میں بزم کہاں ملیں ہم تھے \n",
      "سنائیو خاموشی کردار انوکھا کا جس ہے کیا \n",
      "تن خوں بہ ہے میں گھر نہ جو \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,number_of_stanzas):\n",
    "    for j in range(1,5):\n",
    "      sentence = get_bigram_word(\"123\",0,10,bigrams_dict_probab_bkwd)\n",
    "      if(j%4==0):\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24gTccXjvoid"
   },
   "source": [
    "## Bidirectional Bigrams Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JatW5ss7vn6W",
    "outputId": "5577ae8c-31f9-4d0c-d0f9-5ecf7ed6108f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "چراغ محفل ہے محرم ہے صنم کدہ صنم \n",
      "گدازِ واں ہو تو ہے وہ عشق کی \n",
      "پہنچوں لگا کہ وہ غزنوی وہ عشق کی \n",
      "سُراغِ دود چراغ دود تھا میں تڑپ سجدے فضائیں \n",
      "\n",
      "\n",
      "صرفہ مالی قفس میں نہ مری کوشش کی \n",
      "مقصود یہ کہا تو کہاں سے جس کا \n",
      "تکلف ہمیں اٹھائے نہ مری فریاد سے نہیں \n",
      "آباد قدر آیا ہے نگاہ کی خامشی میں \n",
      "\n",
      "\n",
      "دیمک لیتا کر نہ رہ سکتا سمجھ بلا \n",
      "لگاؤ مہجوری کاشانہ رگ خوں جو قمری سے \n",
      "جنہں گزرا آئی ہے نگاہ بھی تھا پردہ \n",
      "نگہہ ہوائے سیم شوخ نے یہ فضائیں برہنہ \n",
      "\n",
      "\n",
      "آزردگاں آزادی ڈھانپا دیار چھوٹوں آتشِ ہے زلف \n",
      "دام و شب میں آپ اپنی موج دیکھ \n",
      "بڑھتا گھر میں تڑپ رہے گی افلاک مرا \n",
      "مشعل ہے "
     ]
    }
   ],
   "source": [
    "for i in range(1,number_of_stanzas):\n",
    "    for j in range(1,5):\n",
    "      get_bigram_word(\"123\",0,10,bidirectional_dict_probab)\n",
    "      if(j%4==0):\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqjSx6UE8UpB"
   },
   "source": [
    "## Trigrams Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LiUurWlmGvsQ",
    "outputId": "9663f80c-fc8f-4ff3-8dd8-3f8f94116032"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "نہ رکھ امیدِ آزادی دل ز جوئے خوں ہوا کو \n",
      "فصل گل مسجد و بھَوں پاس دیکھو تو خانہ ویراں اب وہ \n",
      "دم لیا تیرے خوابوں کیا جان برہنہ پائی اے کاش میں \n",
      "کچھ اور شے ہےعلم ہے کچھ اور \n",
      "\n",
      "\n",
      "پھر صبا وگرنہ شہر ہر گوشۂ اے طفلِ یہ غزل کیا پوجتا \n",
      "تاراجِ کاوشِ قلندر جز کھویا گیا حاضر ہوں طاعت میں تھا زندگی \n",
      "ہمیشہ تازہ آئیں جس شب فراق ہے یہ قدسیوں سے \n",
      "نہ ہوئی عرضِ سر ہے اب مرا انتظار کر \n",
      "\n",
      "\n",
      "تیغ ہلال یہ رشک کیا کم ہے \n",
      "مشکلیں مجھ نہ تم اب میں اشک پیدا میں پھر گریہ \n",
      "مانندِ کہکشاں عدو کے راہِ صحرائے دیکھ کر شرمائں یہود \n",
      "صد شکر اعلان جنوں وائے محرومیِ نگاہ پاک جو نہیں کوئی کہے \n",
      "\n",
      "\n",
      "یہ شیشہ وہ خاک کہ اندازِ بے طلب غالبؔ خستہ فلک نے \n",
      "فرق ان اسد مت درپردہ انھیں جاں دادہٴ ظلمت ھے میرا قد \n",
      "یہ لاش غنچۂ ناشگفتہ علم میں دست ساقی مصر و فلسطیں \n",
      "عاشقی صبر کسی راستے پرافشاں ہے ورنہ کوئی یہ خلش یار آشنا \n",
      "\n",
      "\n",
      "غیر یوں مری نوا دل گزر خطا کس ہمیشہ تازہ شب کو \n",
      "ہے کہاں وہ دن کہ وجد ذوق میں \n",
      "بس پہلے وگرنہ آگ اب منزلِ سیر کے نگینِ نامِ غم جہاں \n",
      "شہادت تھی یہاں ساقی جاتا وگرنہ دل نازک بو بھی ہوتی \n",
      "\n",
      "\n",
      "بُھولے تو ہے غنیمت بہ ہر ورنہ کیا دیکھیں کیا مشکلیں مجھ \n",
      "خُوب وقت اللہ رے گیسوئے تابدار ننگ بالیدن غبار راہ چرایا زخم \n",
      "جو ایک بہشت مغربیاں ستم پہ اسی اقبالؔ ٹھہر سکا نظر میں \n",
      "ہم رشک ہر اک حلقہٴ گرداب تھا \n",
      "\n",
      "\n",
      "رہی نہ وہ دنیا جنت کا \n",
      "یارب میں تماشائے اہلِ سواے حسرتِ قدر جو خانہ زادِ گزر اوقات \n",
      "ایک بیداد شیخ مکتب کہتا ہوں کہ جان کس \n",
      "شاعری انکی تھے کتنے وفاداری بشرطِ یہ دل غریب سہی \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,number_of_stanzas):\n",
    "    for j in range(1,5):\n",
    "      get_trigram_word(\"123\",\"123\",0,6,trigrams_dict_probab=trigrams_dict_probab)\n",
    "      if(j%4==0):\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uPKhVORBq5x"
   },
   "source": [
    "# Conclusion and Observations:\n",
    "* The unigram model was very basic and was not accurate\n",
    "* The bigram model was better than unigram but not good\n",
    "* Surprisingly, the backward bigram model also provided a better representation of sentences\n",
    "* The Bi-directional bigrams performed really well as compared to backward or plain bigram models\n",
    "* The trigram models were also good but the bidirectoinal bigrams were a clear win.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "i20-2207",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
